{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import logging\n",
    "import pytest\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        filename=r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\log.txt', \n",
    "        format='[%(asctime)s][%(levelname)s] %(message)s',\n",
    "        level=logging.INFO\n",
    "        )\n",
    "\n",
    "df1 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000007N5_20241217-094027.csv', encoding='cp1252')\n",
    "df2 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000003PS_20241217-093537.csv', encoding='cp1252')\n",
    "\n",
    "df2.drop(['typ av IT-tjänst'], axis=1, inplace=True)\n",
    "df1 = df1.drop(['typ av konsekvens','2023'], axis=1).loc[df1['2021']!='..']\n",
    "\n",
    "df1['2021'] = df1['2021'].astype(int)\n",
    "\n",
    "df1 = df1.groupby('redovisningsgrupp').sum()\n",
    "\n",
    "def fix_regions(df):\n",
    "        df.rename(index={'Stockholms län': 'Stockholm', 'Norra mellansverige':'Norra Mellansverige', 'Östra mellansverige':'Östra Mellansverige'}, inplace=True)\n",
    "        \n",
    "        \n",
    "fix_regions(df1)\n",
    "fix_regions(df2)\n",
    "\n",
    "df3 = df1.merge(df2, 'left', right_on='redovisningsgrupp', left_on='redovisningsgrupp')\n",
    "\n",
    "df3.rename(columns={'redovisningsgrupp':'Region', '2021_x':'Incidenter 2021', '2021_y':'Utgifter för IT tjänster 2021'}, inplace=True)\n",
    "\n",
    "con = sql.connect('kunskapskontrol1.db')\n",
    "df3.to_sql('data om it-utgifter och incidenter', con, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m df2 \u001b[38;5;241m=\u001b[39m clean_df2(df2)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Vi kör merge, som tar liknande argument som SQL join, och skapar df3\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m df3 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mredovisningsgrupp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mredovisningsgrupp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m df3\u001b[38;5;241m.\u001b[39mrename(\n\u001b[0;32m     53\u001b[0m     columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredovisningsgrupp\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegion\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021_x\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncidenter 2021\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     55\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021_y\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUtgifter för IT tjänster 2021\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[0;32m     56\u001b[0m     inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m df2\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10813\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10814\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10828\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10829\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10830\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10841\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10842\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:153\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    152\u001b[0m     left_df \u001b[38;5;241m=\u001b[39m _validate_operand(left)\n\u001b[1;32m--> 153\u001b[0m     right_df \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_operand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m             left_df,\n\u001b[0;32m    157\u001b[0m             right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2692\u001b[0m, in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   2691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2693\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only merge Series or DataFrame objects, a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2694\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
     ]
    }
   ],
   "source": [
    "# Kunskapskontrol 1\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        filename=r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\log.txt', \n",
    "        format='[%(asctime)s][%(levelname)s] %(message)s',\n",
    "        level=logging.INFO\n",
    "        )\n",
    "# Läsa in csv från SCB, passa på att specifiera encoding som cp1252 annars får man inte svenska bokstaver\n",
    "try:\n",
    "    df1 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000007N5_20241217-094027.csv', encoding='cp1252')\n",
    "    df2 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000003PS_20241217-093537.csv', encoding='cp1252')\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f'File Not Found, check file path!')\n",
    "else:\n",
    "    logger.info(f'CSV file was read')\n",
    "# rensa df1, droppa 2 kolumner som vi inte behöver samt alla nullvärde i den kolumnen vi håller i.\n",
    "# SCB använder \"..\" som nullvärde så pandas .dropna kommer inte funka\n",
    "# i csv'en är siffrorna klassifierade som textsträngar så vi måste omvändla til int\n",
    "# Vi är egentligen bara intresserad av total incidenter\n",
    "\n",
    "def clean_df1(df1):\n",
    "        df1 = df1.drop(['typ av konsekvens','2023'], axis=1).loc[df1['2021']!='..']\n",
    "        df1['2021'] = df1['2021'].astype(int)\n",
    "        df1 = df1.groupby('redovisningsgrupp').sum()\n",
    "        return df1\n",
    "# SCB använder ibland inte samma exakta namn för regionerna så vi får döpa om värden i första dataframe så de matchar namnen i den andra\n",
    "def fix_regions(*dfs):\n",
    "    for df in dfs:\n",
    "        df.rename(\n",
    "            index={'Stockholms län': 'Stockholm',\n",
    "                   'Norra mellansverige':'Norra Mellansverige',\n",
    "                   'Östra mellansverige':'Östra Mellansverige'},\n",
    "            inplace=True\n",
    "            )\n",
    "        \n",
    "# För df2 kan vi droppa den kolumnen eftersom den bara har värdet \"Totalt\" i alla rader\n",
    "def clean_df2(df):\n",
    "    return df2.drop(['typ av IT-tjänst'], axis=1, inplace=True)\n",
    "\n",
    "df1 = clean_df1(df1)\n",
    "fix_regions(df1, df2)\n",
    "df2 = clean_df2(df2)\n",
    "\n",
    "\n",
    "# Vi kör merge, som tar liknande argument som SQL join, och skapar df3\n",
    "df3 = df1.merge(df2, 'left', right_on='redovisningsgrupp', left_on='redovisningsgrupp')\n",
    "\n",
    "df3.rename(\n",
    "    columns={'redovisningsgrupp':'Region',\n",
    "             '2021_x':'Incidenter 2021',\n",
    "             '2021_y':'Utgifter för IT tjänster 2021'},\n",
    "    inplace=True\n",
    "    )\n",
    "df2.head()\n",
    "df1.head()  \n",
    "df3.head()\n",
    "# con = sql.connect('kunskapskontrol1.db')\n",
    "\n",
    "# try:\n",
    "#     df3.to_sql('data om it-utgifter och incidenter', con, if_exists='replace')\n",
    "# except:\n",
    "#     logger.debug(f'Loading to DB failed')\n",
    "# else:\n",
    "#     logger.info(f'Loading to DB successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Kunskapskontrol 1\n",
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        filename=r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\log.txt', \n",
    "        format='[%(asctime)s][%(levelname)s] %(message)s',\n",
    "        level=logging.INFO\n",
    "        )\n",
    "# Läsa in csv från SCB, passa på att specifiera encoding som cp1252 annars får man inte svenska bokstaver\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000007N5_20241217-094027.csv', encoding='cp1252')\n",
    "    df2 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000003PS_20241217-093537.csv', encoding='cp1252')\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f'File Not Found, check file path!')\n",
    "else:\n",
    "    logger.info(f'CSV file was read')\n",
    "# rensa df1, droppa 2 kolumner som vi inte behöver samt alla nullvärde i den kolumnen vi håller i.\n",
    "# SCB använder \"..\" som nullvärde så pandas .dropna kommer inte funka\n",
    "df1 = df1.drop(\n",
    "    ['typ av konsekvens','2023'], axis=1\n",
    "    ).loc[df1['2021']!='..']\n",
    "# i csv'en är siffrorna klassifierade som textsträngar så vi måste omvändla til int\n",
    "df1['2021'] = df1['2021'].astype(int)\n",
    "# Vi är egentligen bara intresserad av total incidenter\n",
    "df1 = df1.groupby('redovisningsgrupp').sum()\n",
    "# SCB använder ibland inte samma exakta namn för regionerna så vi får döpa om värden i första dataframe så de matchar namnen i den andra\n",
    "def fix_regions(*dfs):\n",
    "    for df in dfs:\n",
    "        df.rename(\n",
    "            index={'Stockholms län': 'Stockholm',\n",
    "                   'Norra mellansverige':'Norra Mellansverige',\n",
    "                   'Östra mellansverige':'Östra Mellansverige'},\n",
    "            inplace=True\n",
    "            )\n",
    "\n",
    "fix_regions(df1, df2)\n",
    "\n",
    "  \n",
    "# För df2 kan vi droppa den kolumnen eftersom den bara har värdet \"Totalt\" i alla rader\n",
    "df2.drop(['typ av IT-tjänst'], axis=1, inplace=True)\n",
    "# Vi kör merge, som tar liknande argument som SQL join, och skapar df3\n",
    "df3 = df1.merge(df2, 'left', right_on='redovisningsgrupp', left_on='redovisningsgrupp')\n",
    "\n",
    "df3.rename(\n",
    "    columns={'redovisningsgrupp':'Region',\n",
    "             '2021_x':'Incidenter 2021',\n",
    "             '2021_y':'Utgifter för IT tjänster 2021'},\n",
    "    inplace=True\n",
    "    )\n",
    "\n",
    "con = sql.connect('kunskapskontrol1.db')\n",
    "\n",
    "try:\n",
    "    df3.to_sql('data om it-utgifter och incidenter', con, if_exists='replace')\n",
    "except:\n",
    "    logger.debug(f'Loading to DB failed')\n",
    "else:\n",
    "    logger.info(f'Loading to DB successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        filename=r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\log.txt', \n",
    "        format='[%(asctime)s][%(levelname)s] %(message)s',\n",
    "        level=logging.INFO\n",
    "        )\n",
    "\n",
    "def csv_reader():\n",
    "    try:\n",
    "        pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000007N5_20241217-094027.csv', encoding='cp1252')\n",
    "        pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000003PS_20241217-093537.csv', encoding='cp1252')\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f'File Not Found, check file path!')\n",
    "    else:\n",
    "        logger.info(f'CSV file was read')\n",
    "        \n",
    "\n",
    "\n",
    "csv_reader()\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   typ av konsekvens    redovisningsgrupp  \\\n",
      "0  otillgängliga it-tjänster pga. fel i hårdvara/...       Stockholms län   \n",
      "1  otillgängliga it-tjänster pga. fel i hårdvara/...  Östra mellansverige   \n",
      "2  otillgängliga it-tjänster pga. fel i hårdvara/...    Småland med öarna   \n",
      "3  otillgängliga it-tjänster pga. fel i hårdvara/...           Sydsverige   \n",
      "4  otillgängliga it-tjänster pga. fel i hårdvara/...          Västsverige   \n",
      "\n",
      "  2021 2023  \n",
      "0   18   16  \n",
      "1   15   23  \n",
      "2   20   16  \n",
      "3   18   15  \n",
      "4   17   14  \n",
      "  typ av IT-tjänst    redovisningsgrupp   2021\n",
      "0           Totalt            Stockholm  36930\n",
      "1           Totalt  Östra Mellansverige   6395\n",
      "2           Totalt    Småland med öarna   7977\n",
      "3           Totalt           Sydsverige   7105\n",
      "4           Totalt          Västsverige  15656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        filename=r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\log.txt', \n",
    "        format='[%(asctime)s][%(levelname)s] %(message)s',\n",
    "        level=logging.INFO\n",
    "        )\n",
    "# Läsa in csv från SCB, passa på att specifiera encoding som cp1252 annars får man inte svenska bokstaver\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000007N5_20241217-094027.csv', encoding='cp1252')\n",
    "    df2 = pd.read_csv(r'C:\\Users\\vidar\\Documents\\Skóli\\TUC\\Data_Science\\Projects\\Kunskapskontrol_1\\000003PS_20241217-093537.csv', encoding='cp1252')\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f'File Not Found, check file path!')\n",
    "else:\n",
    "    logger.info(f'CSV file was read')\n",
    "\n",
    "      \n",
    "def cleaner(df1, df2):\n",
    "    df2.drop(['typ av IT-tjänst'], axis=1, inplace=True)\n",
    "    df1 = df1.drop(['typ av konsekvens','2023'], axis=1).loc[df1['2021']!='..']\n",
    "    df1['2021'] = df1['2021'].astype(int)\n",
    "    df1 = df1.groupby('redovisningsgrupp').sum()\n",
    "    return df1, df2\n",
    "    \n",
    "    \n",
    "def fix_regions(df1):\n",
    "        df1.rename(\n",
    "            index={'Stockholms län': 'Stockholm',\n",
    "                   'Norra mellansverige':'Norra Mellansverige',\n",
    "                   'Östra mellansverige':'Östra Mellansverige'},\n",
    "            inplace=True\n",
    "                  )\n",
    "        \n",
    "def merger(df1, df2):  \n",
    "    df3 = df1.merge(df2, 'left', right_on='redovisningsgrupp', left_on='redovisningsgrupp')\n",
    "    df3.rename(columns={'redovisningsgrupp':'Region', '2021_x':'Incidenter 2021', '2021_y':'Utgifter för IT tjänster 2021'}, inplace=True)\n",
    "    return df3\n",
    "\n",
    "fix_regions\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
